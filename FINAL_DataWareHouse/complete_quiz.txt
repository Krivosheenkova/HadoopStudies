## Что такое Hadoop?
Проект организации Apache Software Foundation,  open source фреймворк, состоящий из набора библиотек и утилит для работы с большими данными, разработки и выполнения программ по обработке данных на кластерах из десятков и тысяч узлов, состоит из четырех компонентов:
1. Hadoop Common
   набор инфраструктурных программных библиотек и утилит, используемых для других модулей и родственных проектов              
2. HDFS
   распределённая файловая система Hadoop             
3. Yarn
   планировщик задач             
4. Hadoop MapReduce
   фреймворк для выполнения распределенных mapreduce-вычислений 

## Что такое HDFS?
  Распределённая, переносимая и масштабируемая файловая система на основе Java, позволяющая хранить информацию практически неограниченного объёма (50TB+). По сравнению с другими файловыми системами (>64MB) HDFS имеет большой размер блока (64 или 128MB). Технология репликации в HDFS позволяет использовать сравнительно недорогое серверное оборудование. Репликация происходит в асинхронном режиме - информация распределяется по нескольким серверам непосредственно во время загрузки, это обеспечит отказоустойчивость файловой системы в целом в случае выхода из строя отдельных узлов.
  Архитектура HDFS включает в себя 4 компонента: NameNode (Master) (RAM), Secondary NameNode (fsimage checkpoint) (optional), DataNode (Slave) (Disk), Клиент (API доступ). Чтобы открыть файл, клиент обращается к NameNode и получает список расположения блоков, составляющих файл. Эти адреса идентифицируют DataNode, который хранит каждый блок. Затем клиенты считывают информацию напрямую с серверов DataNode, возможно, параллельно. NameNode не принимает непосредственного участия в этом обмене объемами данных, сводя его накладные расходы к минимуму. Работа с файлами в HDFS происходит по принципу WORM (Write-once and read-many, один раз записать – много раз прочитать), что полностью освобождает систему от блокировок типа «запись-чтение» - это нужно, чтобы оптимизировать систему под потоковую передачу данных. Также система способна сама отследить сбой и корректно на него отреагировать - каждый узел данных периодически отправляет диагностические сообщения узлу имён, который записывает логи операций над файлами.

## *Что такое YARN?
  Один из основных компонентов Apache Hadoop. Модуль, функционирующий как самостоятельный демон, отвечающий за управление ресурсами кластеров для различных приложений, работающих в кластере Hadoop, и планирование заданий (TaskTracker), выполняемых на узлах кластера. Трекер дает возможность выполнения нескольких заданий единовременно, параллельно и изолированно. 

## Какие минусы или опасные места HDFS?
  1. NameNode является центром всего кластера и её отказ повлечет сбой системы целиком;
  2. Secondary NameNode - не полноценная замена NameNode, а checkpoint, так что часть данных может быть всё же утеряна при сбое сервера имён;
  3. Нельзя дописывать или оставить открытым для записи файлы в HDFS -> невозможно обновлять уже существующие блоки данных;
  4. Отсутствие инструментов для поддержки ссылочной целостности данных, что не гарантирует идентичность реплик. HDFS перекладывает проверку целостности данных на клиентов. При создании файла клиент рассчитывает контрольные суммы каждые 512 байт, которые в последующем сохраняются на сервере имен. При считывании файла клиент обращается к данным и контрольным суммам. В случае их несоответствия происходит обращение к другой реплике.

## Что такое блок HDFS?
Единица хранения и репликации в HDFS (128-256 Мб)

## Для чего используется NameNode?
NameNode хранит дерево каталогов всех файлов в файловой системе метаинформацию о распределении блоков в кластере. 
NameNode очень важен для HDFS, и когда NameNode не работает, кластер HDFS недоступен и считается отключенным.
NameNode знает список блоков и их расположение для любого заданного файла в HDFS. Благодаря этой информации NameNode знает, как построить файл из блоков.

## Для чего используется DataNode?
DataNode хранит блоки файлов. Когда DataNode запускается, она оповещает NameNode и сообщает список блоков, за которые она ответственна.
Если DataNode недоступна, это не влияет на доступность данных на кластере - NameNode организует репликацию непосредственно для тех блоков, которые были в ведении сбойной DataNode.
DataNode требует много места на диске, так как хранит фактические данные.

## Что будет, если записать много маленьких файлов в HDFS?
Заполнится память центрального сервера системы - сервера имён.

## Что будет, если несколько DataNode внезапно отключатся?
NameNode всегда отслеживает соответствие заданному коэффициенту репликации. DataNode перодически отправляет сообщения HeartBeat на вход NameNode, так что при отсутствии этого сообщения NameNode отмечает блоки на сбойной DataNode мёртвыми, а затем проверка репликаций повлечет создание новых реплик, если это необходимо.

## Как проадпейдить несколько записи в большом файле на hdfs?
Никак. Файл в HDFS может записан только однажды и не может быть изменен. 

## *Почему задачи на YARN нестабильны?
???

## Что такое Hive?
Первая и наиболее популярная система управления базами данных, которая использует батчевую обработку данных, что делает ее довольно мощной по сравнению с обычными СУБД в работе с большими массивами данных.

## Что хранит HiveMetastore?
Hive хранит свою базу данных и метаданные созданных объектов (имена колонок, типы, комментарии и т.д.) в HiveMetastore (также известен как HCatalog) 

## Чем отличается external table и managed table?
Managed table рекомендуется использовать тогда, когда Hive должен управлять жизненным циклом таблицы или при генерации временных таблиц. Если таблица или партиция типа managed удалена, то данные и метаданные, ассоциированные с этой таблицей (или партицией) будут также удалены. Если опция PURGE не задана, данные будут временно перемещены в корзину .Trash.
--
External table рекомендуется использовать тогда, когда файлы уже существуют или находятся на remote locations и если файлы не должны быть удалены при удалении таблицы (партиции) в Hive.
External table описывает метаданные/схему внешних файлов. Доступ к файлам external table и управление ими могут осуществляться процессами за пределами hive. Таблицы типа EXTERNAL могут также получать доступ к удаленным расположениям HDFS. Если структура или вариант партиционирования изменился, есть возможность обновить метаданные таблицы с помощью команды msck repair table.

## *Какие форматы умеет читать Hive?
Встроенные сериализаторы/десериализаторы:
- Avro (Hive >=0.9.1)
- ORC (Hive >=0.11)
- RegEx
- Thrift
- Parquet (Hive >=0.13)
- CSV (Hive >=0.14)
- JsonSerDe (Hive 0.12 и более поздние версии в hcatalog-core)

## *Чем отличается управление ресурсов в Hive и Impala?
Hive использует фреймворк MapReduce в качестве движка дефакто для выполнения запросов. 
> MapReduce - программный фреймворк для написания приложений, работающих с большими объемами данных с использованием параллелизации на больших кластерах стандартного оборудования. Задание MapReduce разбивает входные данные на части, которые обрабатываются в рамках парадигмы map/reduce.
Управление ресурсами Apache Impala осуществляется с помощью настройки пулов ресурсов. Для этого следует определить следующие параметры: макс. кол-во выполняемых запросов / макс. кол-во запросов в очереди, ограничение памяти для запросов по умолчанию, максимальный объём памяти, тайм-аут очереди (этот параметр определяется параллелизмом, продолжительностью и соглашением об уровне обслуживания SLA).

##  Чем отличается колочный формат хранения данных от строчного?
Если данные в базу быстро изменяются/добавляются целесообразно использовать строчный формат, и напротив, если данные изменяются редко/не изменяются и имеет место многократное чтение - логично использовать поколоночный вариант хранения, чтобы иметь возможность ограничить запрос несколькими колонками вместо сканирования целой таблицы.
Есть различия в производительности: при построчнои хранении чтение с диска будет происходить более линейно - меньшее число пробросов головок жесткого диска ожидаемо более эффективно. Более предсказуемое поведение операций чтения позволяет операционной системе лучше использовать дисковый кэш, что имеет значение даже для SSD дисков, т.к. загрузка по преположению (read ahead) чаще приводит к успеху.
При строчном хранении возникает (минимум одна) блокировка на запись, которая может затронуть значительную часть таблицы. В поколоночном варианте такое происходит гораздо чаще, но наносят меньше ущерба т.к. касаются только конкретной колонки.

##  Чем отличается parquet/orc от csv?
CSV хранит данные построчно, а parquet и orc - поколоночно. Разница эффективности использования форматов csv и parquet/orc колоссальная, а между parquet и orc - минимальная.

##  Чем отличается Avro от json?
Библиотеки JSON реализованы на языке C, а avro использует простой Ruby, так что avro может проигрывать JSON в производительности, однако avro используют тогда, когда нужно уменьшить размер файлов или создать строгую схему.

##  *Чем отличается документориетированный формат данных от реляционного?
Реляционные базы данных не дублируют данные, имеют "плоские" конструкции, фокусируются на сущностях и их отношениях и запросы и индексы обычно создаются после разработки модели данных. В документоориентированных моделях отношения объектов не имеют такого значения. Данные, которые обычно читаются вместе будут храниться вместе в документоориентированной базе.
Документоориентированные БД определяются как schema-on-read (структура данных неявна и их интерпретация происходит при чтении), а реляционные - как schema-on-write (традиционный подход реляционных бд, при котором база гарантирует строгое  соответствие записываемых данных определенной схеме). scheme-on-read аналогична динамической (во время выполнения) проверке типов данных в разных языках программирования, в то время как scheme-on-read аналогична статической (во время компиляции). 
Следует использовать документоориентированный формат, если структура элементов множества различается, т.е. данные разнородны. 
Документы обычно хранятся в виде единых непрерывных строк, закодированных в формат JSON, XML или их двоичную разнновидность BSON. Локальность хранилища дает преимущества, если приложению часто требуется доступ ко всему документу, ведь если данные разбиты по нескольким таблицам, потребуется несколько запросов по индексу, что потребует больше операций дискового поиска и займет больше времени. Однако это работает только тогда, когда требуется получить большие части документа за раз. База обычно загружает весь документ целиком, даже если вам нужен всего один фрагмент. Обновление данных документа зачастую влечет переписывание документа целиком. Таким образом важно ограничивать размеры документов и избегать увеличивающих этот размер операций записи. Некоторые реляционные СУБД предоставляют возможность управления локальностью запросов с помощью, например, многотабличных кластеризованных индекс-таблиц (multi-table index cluster table) (Oracle), column-family (Cassandra, HBase) благодаря тому, что схема способна объявить о необходимости вложенности строк таблицы внутри родительской.
Еще более выгодным может оказаться совмещение реляционных и документоориентированных баз. Некоторые реляционные СУБД, вроде PostgreSQL (>=9.3), MySQL (>=5.7) и IBM DB2 (>=10.5) предоставляют поддержку типа JSON. Также и некоторые документоориентированные базы данных двигаются навстречу реляционным: RethinkDB пооддерживает в своем языке запросов отношения, подобные реляционным, а некоторые драйвера MongoDB автоматически разрешают ссылки на БД.

##  Чем отличается etl и elt?


##  Какие основные челенджи etl?
##  *Какие инструменты etl вы знаете?
##  Для чего нужны key-value СУБД?
##  *Какие сложности стриминга в hdfs?
##  *Какие минусы key-value хранилищ?
##  Из чего состоит хранилище данных?
##  Какие виды хранилищ данных вы знаете?
##  *Основные задачи Data governance?

SLA https://habr.com/ru/post/336868/ 
Comparison Article about popular data formats https://www.adaltas.com/en/2021/03/22/performance-comparison-of-file-formats/
